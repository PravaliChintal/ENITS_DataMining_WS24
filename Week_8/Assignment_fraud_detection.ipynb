{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fm7TyhkUSnDf"
      },
      "source": [
        "# Assignment: Credit Card Fraud Detection revised\n",
        "\n",
        "we return to the credit card use case (last time we used Random Forests).\n",
        "\n",
        "\n",
        "## Pre-Stage\n",
        "Use your pre-processing from the last assignment as input.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "scrolled": false,
        "id": "aWV_Fsf4SnDj",
        "outputId": "0d849f89-ba7e-4b4d-885b-792d1929f777",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DATA'...\n",
            "remote: Enumerating objects: 126, done.\u001b[K\n",
            "remote: Counting objects: 100% (39/39), done.\u001b[K\n",
            "remote: Compressing objects: 100% (28/28), done.\u001b[K\n",
            "remote: Total 126 (delta 11), reused 39 (delta 11), pack-reused 87 (from 1)\u001b[K\n",
            "Receiving objects: 100% (126/126), 185.56 MiB | 11.56 MiB/s, done.\n",
            "Resolving deltas: 100% (32/32), done.\n",
            "Updating files: 100% (86/86), done.\n"
          ]
        }
      ],
      "source": [
        "#download data\n",
        "#get the data\n",
        "!git clone https://github.com/keuperj/DATA.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "U3NmIO97SnDl",
        "outputId": "0dd7e5cc-82d3-403d-a8ef-f5e2b123d5b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  DATA/creditcard.csv.zip\n",
            "  inflating: creditcard.csv          \n"
          ]
        }
      ],
      "source": [
        "!unzip DATA/creditcard.csv.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ToxIEK8OSnDl"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv(\"creditcard.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5ts_Jv9QSnDm"
      },
      "outputs": [],
      "source": [
        "# your preprocessing code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzeXpAf9SnDm"
      },
      "source": [
        "# Task: Train a MLP-Network\n",
        "* Train and evaluate the model\n",
        "* Compare the results to the Random Forrest\n",
        "* Tune the hyper-parameters (like number of layers, neurons per layer, learning-rate and number of epochs ) to optimize the results\n",
        "\n",
        "See: https://keras.io/api/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qe2puKjnSnDm",
        "outputId": "c797f965-01c0-4c36-b241-3f7abc1d77d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MLP Accuracy: 0.999385555282469\n",
            "Random Forest Accuracy: 0.9995611109160493\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56864\n",
            "           1       0.94      0.68      0.79        98\n",
            "\n",
            "    accuracy                           1.00     56962\n",
            "   macro avg       0.97      0.84      0.90     56962\n",
            "weighted avg       1.00      1.00      1.00     56962\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     56864\n",
            "           1       0.97      0.77      0.86        98\n",
            "\n",
            "    accuracy                           1.00     56962\n",
            "   macro avg       0.99      0.88      0.93     56962\n",
            "weighted avg       1.00      1.00      1.00     56962\n",
            "\n",
            "[[56860     4]\n",
            " [   31    67]]\n",
            "[[56862     2]\n",
            " [   23    75]]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "X=data.drop('Class',axis=1)\n",
        "y=data['Class']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=42)\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(100,), activation='relu', solver='adam', max_iter=100)\n",
        "mlp.fit(X_train_scaled, y_train)\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train_scaled, y_train)\n",
        "y_pred_mlp = mlp.predict(X_test_scaled)\n",
        "y_pred_rf = rf.predict(X_test_scaled)\n",
        "print(\"MLP Accuracy:\", accuracy_score(y_test, y_pred_mlp))\n",
        "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
        "\n",
        "print(classification_report(y_test, y_pred_mlp))\n",
        "print(classification_report(y_test, y_pred_rf))\n",
        "\n",
        "# Confusion matrices\n",
        "print(confusion_matrix(y_test, y_pred_mlp))\n",
        "print(confusion_matrix(y_test, y_pred_rf))\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    'hidden_layer_sizes': [(100,), (50, 50), (100, 50)],\n",
        "    'activation': ['relu', 'tanh','logistic'],\n",
        "    'solver': ['adam', 'sgd'],\n",
        "    'alpha': [0.0001, 0.001, 0.01],\n",
        "  'learning_rate': ['constant', 'adaptive'],\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(MLPClassifier(), param_grid, cv=5)\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "best_mlp = grid_search.best_estimator_"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}